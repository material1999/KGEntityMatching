{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-13T22:16:09.577448Z",
     "start_time": "2025-07-13T22:16:06.535150Z"
    }
   },
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:16:09.671413Z",
     "start_time": "2025-07-13T22:16:09.669691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "big = \"memoryalpha\"\n",
    "small = \"stexpanded\"\n",
    "embeddings = \"dogtag_bgelarge\"\n",
    "top = 1000"
   ],
   "id": "d87649d0a3987683",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:16:09.686868Z",
     "start_time": "2025-07-13T22:16:09.684086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mappings_file_small = \"./_input/mappings/\" + small + \".json\"\n",
    "mappings_file_big = \"./_input/mappings/\" + big + \".json\"\n",
    "\n",
    "node_embeddings_small_file = \"./_input/node_embeddings/\" + embeddings + \"/\" + small + \".json\"\n",
    "node_embeddings_big_file = \"./_input/node_embeddings/\" + embeddings + \"/\" + big + \".json\"\n",
    "\n",
    "neighborhood_embeddings_small_file = \"./_input/neighborhood_embeddings/\" + embeddings + \"/\" + small + \".json\"\n",
    "neighborhood_embeddings_big_file = \"./_input/neighborhood_embeddings/\" + embeddings + \"/\" + big + \".json\"\n",
    "\n",
    "exact_match_file = \"./_input/exact_match/\" + big + \"-\" + small + \".json\"\n",
    "gold_pairs_file = \"./_input/gold_pairs/\" + big + \"-\" + small + \".txt\""
   ],
   "id": "9b4a6dcbcf0757b2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:16:44.654812Z",
     "start_time": "2025-07-13T22:16:09.700060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(mappings_file_small) as file:\n",
    "    mappings_small = json.load(file)\n",
    "    mappings_small = {str(v): k for k, v in mappings_small.items()}\n",
    "    mappings_small_reversed = {v: k for k, v in mappings_small.items()}\n",
    "\n",
    "with open(mappings_file_big) as file:\n",
    "    mappings_big = json.load(file)\n",
    "    mappings_big = {str(v): k for k, v in mappings_big.items()}\n",
    "    mappings_big_reversed = {v: k for k, v in mappings_big.items()}\n",
    "\n",
    "with open(node_embeddings_small_file) as nesf:\n",
    "    node_embeddings_small = json.load(nesf)\n",
    "    node_embeddings_small = {mappings_small_reversed[k]: v for k, v in node_embeddings_small.items()}\n",
    "\n",
    "with open(node_embeddings_big_file) as nebf:\n",
    "    node_embeddings_big = json.load(nebf)\n",
    "    node_embeddings_big = {mappings_big_reversed[k]: v for k, v in node_embeddings_big.items()}\n",
    "\n",
    "with open(neighborhood_embeddings_small_file) as eesf:\n",
    "    neighborhood_embeddings_small = json.load(eesf)\n",
    "\n",
    "with open(neighborhood_embeddings_big_file) as eebf:\n",
    "    neighborhood_embeddings_big = json.load(eebf)\n",
    "\n",
    "with open(gold_pairs_file) as gpf:\n",
    "    gold_pairs = []\n",
    "    for line in gpf:\n",
    "        numbers_list = [int(num) for num in line.strip().split(\";\")]\n",
    "        gold_pairs.append(numbers_list)\n",
    "\n",
    "with open(exact_match_file) as file:\n",
    "    exact_match = json.load(file)"
   ],
   "id": "f12028cb602403d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:16:45.299864Z",
     "start_time": "2025-07-13T22:16:45.244052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gold_exact = list()\n",
    "gold_not_exact = list()\n",
    "\n",
    "for p in gold_pairs:\n",
    "    if [p[0], p[1]] in exact_match:\n",
    "        gold_exact.append([p[0], p[1]])\n",
    "    else:\n",
    "        gold_not_exact.append([p[0], p[1]])\n",
    "\n",
    "# neighborhood_embeddings_small_list = list()\n",
    "# neighborhood_ids_small_list = list()\n",
    "\n",
    "node_embeddings_small_list = list()\n",
    "node_ids_small_list = list()\n",
    "\n",
    "neighborhood_embeddings_big_list = list()\n",
    "neighborhood_ids_big_list = list()\n",
    "\n",
    "# for k, v in neighborhood_embeddings_small.items():\n",
    "#     neighborhood_ids_small_list.append(k)\n",
    "#     neighborhood_embeddings_small_list.append(v)\n",
    "\n",
    "for k, v in node_embeddings_small.items():\n",
    "    node_ids_small_list.append(k)\n",
    "    node_embeddings_small_list.append(v)\n",
    "\n",
    "for k, v in neighborhood_embeddings_big.items():\n",
    "    neighborhood_ids_big_list.append(k)\n",
    "    neighborhood_embeddings_big_list.append(v)"
   ],
   "id": "1bf3506ebe7eda",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:17:06.594884Z",
     "start_time": "2025-07-13T22:16:45.572744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensor_small = torch.Tensor(neighborhood_embeddings_small_list)\n",
    "tensor_small = torch.Tensor(node_embeddings_small_list)\n",
    "tensor_big = torch.Tensor(neighborhood_embeddings_big_list)\n",
    "neighborhood_order = util.semantic_search(tensor_small, tensor_big, top_k=top)"
   ],
   "id": "9bd58c97a518bffb",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:17:12.450712Z",
     "start_time": "2025-07-13T22:17:07.559531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "top_dict = dict()\n",
    "for idx, (node_id, order) in enumerate(zip(node_ids_small_list, neighborhood_order)):\n",
    "    items_list = list()\n",
    "    for item in order:\n",
    "        items_list.append((neighborhood_ids_big_list[item['corpus_id']], item['score']))\n",
    "    top_dict[node_id] = items_list"
   ],
   "id": "3c7c4a5d23889fad",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:37:49.239565Z",
     "start_time": "2025-07-13T22:17:55.129893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "node_sim_weight = 1\n",
    "neighborhood_sim_weight = 0.2\n",
    "\n",
    "top_dict_reordered = dict()\n",
    "for k, v in tqdm(top_dict.items()):\n",
    "    # print(mappings_small[k])\n",
    "    # print(\"-----\")\n",
    "    embedding1 = node_embeddings_small[k]\n",
    "    items_list = list()\n",
    "    for item in v:\n",
    "        embedding2 = node_embeddings_big[item[0]]\n",
    "        cosine_sim = np.dot(embedding1, embedding2)\n",
    "        # new_value = float(neighborhood_sim_weight * item[1] + node_sim_weight * cosine_sim)\n",
    "        new_value = float(cosine_sim)\n",
    "        items_list.append((item[0], new_value))\n",
    "        # print(mappings_big[item[0]])\n",
    "        # print(item[1], \"+\", cosine_sim, \"=\", new_value)\n",
    "    top_dict_reordered[k] = items_list"
   ],
   "id": "d5b7d15c0edfc44e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15514/15514 [19:54<00:00, 12.99it/s]  \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:38:04.743463Z",
     "start_time": "2025-07-13T22:37:58.536547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key in top_dict_reordered:\n",
    "    top_dict_reordered[key] = sorted(top_dict_reordered[key], key=lambda x: x[1], reverse=True)"
   ],
   "id": "6f4fe63fa78239a7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T22:45:19.831443Z",
     "start_time": "2025-07-13T22:45:19.472860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"############### SETTINGS ################\")\n",
    "print(\"From:            \" + small)\n",
    "print(\"To:              \" + big)\n",
    "print(\"Embeddings:      \" + embeddings)\n",
    "\n",
    "print(\"############ ALL GOLD PAIRS #############\")\n",
    "print(\"Count:           \" + str(len(gold_pairs)))\n",
    "\n",
    "found = 0\n",
    "skipped = 0\n",
    "all_pairs = len(gold_pairs)\n",
    "# for gold_pair in tqdm(gold_pairs):\n",
    "for gold_pair in gold_pairs:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    for i in range(0, 1000):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"Skipped:         \" + str(skipped))\n",
    "print(\"In Top 1000:     \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_pairs)\n",
    "# for gold_pair in tqdm(gold_pairs):\n",
    "for gold_pair in gold_pairs:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 100):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 100:      \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_pairs)\n",
    "# for gold_pair in tqdm(gold_pairs):\n",
    "for gold_pair in gold_pairs:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 10):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 10:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_pairs)\n",
    "# for gold_pair in tqdm(gold_pairs):\n",
    "for gold_pair in gold_pairs:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Top 1:           \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_pairs)\n",
    "# for gold_pair in tqdm(gold_pairs):\n",
    "for gold_pair in gold_pairs:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict_reordered.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Reordered:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "print(\"############## EXACT MATCH ##############\")\n",
    "print(\"Count:           \" + str(len(gold_exact)))\n",
    "\n",
    "found = 0\n",
    "skipped = 0\n",
    "all_pairs = len(gold_exact)\n",
    "# for gold_pair in tqdm(gold_exact):\n",
    "for gold_pair in gold_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    for i in range(0, 1000):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"Skipped:         \" + str(skipped))\n",
    "print(\"In Top 1000:     \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_exact)\n",
    "# for gold_pair in tqdm(gold_exact):\n",
    "for gold_pair in gold_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 100):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 100:      \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_exact)\n",
    "# for gold_pair in tqdm(gold_exact):\n",
    "for gold_pair in gold_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 10):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 10:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_exact)\n",
    "# for gold_pair in tqdm(gold_exact):\n",
    "for gold_pair in gold_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Top 1:           \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_exact)\n",
    "# for gold_pair in tqdm(gold_exact):\n",
    "for gold_pair in gold_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict_reordered.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Reordered:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "print(\"############ NOT EXACT MATCH ############\")\n",
    "print(\"Count:           \" + str(len(gold_not_exact)))\n",
    "\n",
    "found = 0\n",
    "skipped = 0\n",
    "all_pairs = len(gold_not_exact)\n",
    "# for gold_pair in tqdm(gold_not_exact):\n",
    "for gold_pair in gold_not_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "    for i in range(0, 1000):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"Skipped:         \" + str(skipped))\n",
    "print(\"In Top 1000:     \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_not_exact)\n",
    "# for gold_pair in tqdm(gold_not_exact):\n",
    "for gold_pair in gold_not_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 100):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 100:      \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_not_exact)\n",
    "# for gold_pair in tqdm(gold_not_exact):\n",
    "for gold_pair in gold_not_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    for i in range(0, 10):\n",
    "        if top_dict.get(str(gold_pair[1]))[i][0] == str(gold_pair[0]):\n",
    "            found += 1\n",
    "            break\n",
    "print(\"In Top 10:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_not_exact)\n",
    "# for gold_pair in tqdm(gold_not_exact):\n",
    "for gold_pair in gold_not_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Top 1:           \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")\n",
    "\n",
    "found = 0\n",
    "all_pairs = len(gold_not_exact)\n",
    "# for gold_pair in tqdm(gold_not_exact):\n",
    "for gold_pair in gold_not_exact:\n",
    "    if top_dict.get(str(gold_pair[1])) is None:\n",
    "        continue\n",
    "    if top_dict_reordered.get(str(gold_pair[1]))[0][0] == str(gold_pair[0]):\n",
    "        found += 1\n",
    "print(\"Reordered:       \" + str(found) + \" (\" + f\"{found / all_pairs * 100:.5f}\" + \"%)\")"
   ],
   "id": "64fec82258ebe704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### SETTINGS ################\n",
      "From:            stexpanded\n",
      "To:              memoryalpha\n",
      "Embeddings:      dogtag_bgelarge\n",
      "############ ALL GOLD PAIRS #############\n",
      "Count:           1779\n",
      "Skipped:         0\n",
      "In Top 1000:     1600 (89.93817%)\n",
      "In Top 100:      1292 (72.62507%)\n",
      "In Top 10:       676 (37.99888%)\n",
      "Top 1:           109 (6.12704%)\n",
      "Reordered:       1347 (75.71669%)\n",
      "############## EXACT MATCH ##############\n",
      "Count:           1617\n",
      "Skipped:         0\n",
      "In Top 1000:     1471 (90.97093%)\n",
      "In Top 100:      1187 (73.40754%)\n",
      "In Top 10:       617 (38.15708%)\n",
      "Top 1:           100 (6.18429%)\n",
      "Reordered:       1262 (78.04576%)\n",
      "############ NOT EXACT MATCH ############\n",
      "Count:           162\n",
      "Skipped:         0\n",
      "In Top 1000:     129 (79.62963%)\n",
      "In Top 100:      105 (64.81481%)\n",
      "In Top 10:       59 (36.41975%)\n",
      "Top 1:           9 (5.55556%)\n",
      "Reordered:       85 (52.46914%)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "31f47c529f5212f3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
