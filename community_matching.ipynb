{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ],
   "id": "d9164b8d5151b111",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "big = \"memoryalpha\"\n",
    "small = \"stexpanded\"\n",
    "\n",
    "mapping_file_big = \"./data/triples_v2/\" + big + \"_mapping.json\"\n",
    "mapping_file_small = \"./data/triples_v2/\" + small + \"_mapping.json\"\n",
    "exact_match_file = \"./data/exact_match/\" + big + \"-\" + small + \".json\"\n",
    "\n",
    "communities_big_file = \"./data/one_step/\" + big + \".csv\"\n",
    "communities_small_file = \"./data/one_step/\" + small + \".csv\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(exact_match_file) as emf, open(mapping_file_big) as mfb, open(mapping_file_small) as mfs:\n",
    "    exact_match = json.load(emf)\n",
    "    mapping_big = json.load(mfb)\n",
    "    mapping_small = json.load(mfs)\n",
    "\n",
    "    big_id_dict = {key: value for key, value in mapping_big.items()}\n",
    "    small_id_dict = {key: value for key, value in mapping_small.items()}\n",
    "    \n",
    "    formatted_json = []\n",
    "    for pair in exact_match:\n",
    "        big_id = big_id_dict.get(pair[0])\n",
    "        small_id = small_id_dict.get(pair[1])\n",
    "        if big_id and small_id:\n",
    "            formatted_json.append([big_id, small_id])\n",
    "\n",
    "    # with open('formatted.json', 'w') as outfile:\n",
    "        # json.dump(formatted_json, outfile, indent=4)\n",
    "# print(formatted_json)"
   ],
   "id": "e530e5547259611f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "in_exact_match_big_file = \"./data/one_step_in_exact_match/\" + big + \".csv\"\n",
    "in_exact_match_small_file = \"./data/one_step_in_exact_match/\" + small + \".csv\"\n",
    "\n",
    "big_id_keep = set()\n",
    "small_id_keep = set()\n",
    "\n",
    "for pair in formatted_json:\n",
    "    big_id_keep.add(pair[0])\n",
    "    small_id_keep.add(pair[1])\n",
    "\n",
    "with open(communities_big_file, \"r\") as cbf, open(in_exact_match_big_file, \"w\") as output:\n",
    "    for line in cbf:\n",
    "        numbers = [int(num) for num in line.split(';')]\n",
    "        for number in numbers:\n",
    "            if number in big_id_keep:\n",
    "                output.write(str(number) + \";\")\n",
    "        output.write(\"\\n\")\n",
    "\n",
    "with open(communities_small_file, \"r\") as csf, open(in_exact_match_small_file, \"w\") as output:\n",
    "    for line in csf:\n",
    "        numbers = [int(num) for num in line.split(';')]\n",
    "        for number in numbers:\n",
    "            if number in small_id_keep:\n",
    "                output.write(str(number) + \";\")\n",
    "        output.write(\"\\n\")"
   ],
   "id": "af295ff9cfdf55da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "small_communities = []\n",
    "big_communities = []\n",
    "\n",
    "with open(in_exact_match_big_file) as cbf, open(in_exact_match_small_file) as csf:\n",
    "    \n",
    "    for line in csf:\n",
    "        numbers_set = {int(num) for num in line.strip().split(';')[:-1]}\n",
    "        small_communities.append(numbers_set)\n",
    "\n",
    "    for line in cbf:\n",
    "        numbers_set = {int(num) for num in line.strip().split(';')[:-1]}\n",
    "        big_communities.append(numbers_set)\n",
    "\n",
    "exact_match_count_dict = dict()\n",
    "for id_big, id_small in formatted_json:\n",
    "    print(id_big, id_small)\n",
    "    indexes_big = [index for index, s in enumerate(big_communities) if id_big in s]\n",
    "    indexes_small = [index for index, s in enumerate(small_communities) if id_small in s]\n",
    "    print(indexes_big)\n",
    "    print(indexes_small)\n",
    "    for i_big in indexes_big:\n",
    "        for i_small in indexes_small:\n",
    "            if i_big in exact_match_count_dict:\n",
    "                exact_match_count_dict[(i_big, i_small)] += 1\n",
    "            else:\n",
    "                exact_match_count_dict[(i_big, i_small)] = 1\n",
    "    print(\"#############################################\")\n",
    "\n",
    "    # line_num = 0\n",
    "    # for line in cbf:\n",
    "    #     line_num += 1\n",
    "    #     best_match = None\n",
    "    #     max_match = 0\n",
    "    #     numbers_set = {int(num) for num in line.strip().split(';')[:-1]}\n",
    "    #     comm_num = 0\n",
    "    #     for community in tqdm(small_communities):\n",
    "    #         comm_num += 1\n",
    "    #         match_count = 0\n",
    "    #         for node in community:\n",
    "    #             for number in numbers_set:\n",
    "    #                 if [number, node] in formatted_json:\n",
    "    #                     match_count += 1\n",
    "    #         if match_count > max_match:\n",
    "    #             best_match = comm_num\n",
    "    #             max_match = match_count\n",
    "    #             print(str(line_num) + \" --- \" + str(best_match) + \" --- \" + str(max_match) + \"\\n\")"
   ],
   "id": "351ec2e9bbc0f02f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fed0609d20e8d4b5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
